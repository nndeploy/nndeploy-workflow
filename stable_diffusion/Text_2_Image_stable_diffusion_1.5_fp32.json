{
    "key_": "nndeploy.dag.Graph",
    "name_": "Text_2_Image_stable_diffusion_1.5_fp32",
    "developer_": "zuiren",
    "source_": "https://github.com/CompVis/stable-diffusion",
    "desc_": "Stable Diffusion is a text-to-image model that generates high-quality images from textual descriptions using the stable_diffusion_1.5 model.",
    "device_type_": "kDeviceTypeCodeCpu:0",
    "version_": "1.0.0",
    "required_params_": [],
    "is_dynamic_input_": false,
    "inputs_": [],
    "is_dynamic_output_": false,
    "outputs_": [],
    "is_graph_": true,
    "parallel_type_": "kParallelTypeNone",
    "is_inner_": false,
    "node_type_": "Intermediate",
    "is_time_profile_": false,
    "is_debug_": false,
    "is_external_stream_": false,
    "is_graph_node_share_stream_": true,
    "queue_max_size_": 16,
    "is_loop_max_flag_": true,
    "loop_count_": -1,
    "image_url_": [
        "template[http,modelscope]@https://template.cn/template.jpg"
    ],
    "video_url_": [
        "template[http,modelscope]@https://template.cn/template.mp4"
    ],
    "audio_url_": [
        "template[http,modelscope]@https://template.cn/template.mp3"
    ],
    "model_url_": [
        "modelscope@nndeploy/nndeploy:stable_diffusion/fp32/tokenizer/tokenizer.json",
        "modelscope@nndeploy/nndeploy:stable_diffusion/fp32/text_encoder/model.onnx",
        "modelscope@nndeploy/nndeploy:stable_diffusion/fp32/vae_decoder/model.onnx",
        "modelscope@nndeploy/nndeploy:stable_diffusion/fp32/unet/model.onnx",
        "modelscope@nndeploy/nndeploy:stable_diffusion/fp32/unet/weights.pb"
    ],
    "other_url_": [
        "template[http,modelscope]@https://template.cn/template.txt"
    ],
    "node_repository_": [
        {
            "key_": "nndeploy::tokenizer::TokenizerEncodeCpp",
            "name_": "TokenizerEncodeCpp_3",
            "developer_": "",
            "source_": "",
            "desc_": "A tokenizer encode node that uses the C++ tokenizers library to encode text into token IDs. Supports HuggingFace and BPE tokenizers. Can encode single strings or batches of text. Provides vocabulary lookup and token-to-ID conversion.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "InitTokenText_16@output_0",
                    "type_": "TokenizerText"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "TokenizerEncodeCpp_3@output_0",
                    "type_": "TokenizerIds"
                }
            ],
            "node_type_": "Intermediate",
            "param_": {
                "required_params_": [
                    "tokenizer_type_"
                ],
                "is_path_": true,
                "tokenizer_type_": "kTokenizerTypeHF",
                "json_blob_": "resources/models/stable_diffusion/fp32/tokenizer/tokenizer.json",
                "model_blob_": "",
                "vocab_blob_": "",
                "merges_blob_": "",
                "added_tokens_": "",
                "max_length_": 77
            },
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::tokenizer::TokenizerEncodeCpp",
            "name_": "TokenizerEncodeCpp_4",
            "developer_": "",
            "source_": "",
            "desc_": "A tokenizer encode node that uses the C++ tokenizers library to encode text into token IDs. Supports HuggingFace and BPE tokenizers. Can encode single strings or batches of text. Provides vocabulary lookup and token-to-ID conversion.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "InitTokenText_17@output_0",
                    "type_": "TokenizerText"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "TokenizerEncodeCpp_4@output_0",
                    "type_": "TokenizerIds"
                }
            ],
            "node_type_": "Intermediate",
            "param_": {
                "required_params_": [
                    "tokenizer_type_"
                ],
                "is_path_": true,
                "tokenizer_type_": "kTokenizerTypeHF",
                "json_blob_": "resources/models/stable_diffusion/fp32/tokenizer/tokenizer.json",
                "model_blob_": "",
                "vocab_blob_": "",
                "merges_blob_": "",
                "added_tokens_": "",
                "max_length_": 77
            },
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::stable_diffusion::CvtTokenIds2Tensor",
            "name_": "CvtTokenIds2Tensor_5",
            "developer_": "",
            "source_": "",
            "desc_": "Convert TokenizerIds to int32 NC tensor with BOS=49406 and PAD=49407.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "TokenizerEncodeCpp_3@output_0",
                    "type_": "TokenizerIds"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "CvtTokenIds2Tensor_5@output_0",
                    "type_": "Tensor"
                }
            ],
            "node_type_": "Intermediate",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::stable_diffusion::CvtTokenIds2Tensor",
            "name_": "CvtTokenIds2Tensor_6",
            "developer_": "",
            "source_": "",
            "desc_": "Convert TokenizerIds to int32 NC tensor with BOS=49406 and PAD=49407.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "TokenizerEncodeCpp_4@output_0",
                    "type_": "TokenizerIds"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "CvtTokenIds2Tensor_6@output_0",
                    "type_": "Tensor"
                }
            ],
            "node_type_": "Intermediate",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::infer::Infer",
            "name_": "Infer_7",
            "developer_": "",
            "source_": "",
            "desc_": "Universal Inference Node - Enables cross-platform model deployment with multiple inference backends while maintaining native performance",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": true,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "CvtTokenIds2Tensor_5@output_0",
                    "type_": "Tensor"
                }
            ],
            "is_dynamic_output_": true,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "Infer_7@output_0",
                    "type_": "Tensor"
                }
            ],
            "node_type_": "Intermediate",
            "type_": "kInferenceTypeOnnxRuntime",
            "param_": {
                "required_params_": [
                    "inference_type_",
                    "model_type_",
                    "model_value_",
                    "device_type_"
                ],
                "model_type_": "kModelTypeOnnx",
                "is_path_": true,
                "model_value_": [
                    "resources/models/stable_diffusion/fp32/text_encoder/model.onnx"
                ],
                "external_model_data_": [
                    ""
                ],
                "device_type_": "kDeviceTypeCodeCpu:0",
                "num_thread_": 4,
                "gpu_tune_kernel_": 1,
                "input_num_": 1,
                "input_name_": [
                    ""
                ],
                "input_shape_": [
                    [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                ],
                "output_num_": 1,
                "output_name_": [
                    ""
                ],
                "encrypt_type_": "kEncryptTypeNone",
                "license_": "",
                "share_memory_mode_": "kShareMemoryTypeNoShare",
                "precision_type_": "kPrecisionTypeFp32",
                "power_type_": "kPowerTypeNormal",
                "is_dynamic_shape_": false,
                "min_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "opt_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "max_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "parallel_type_": "kParallelTypeNone",
                "worker_num_": 1
            },
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::infer::Infer",
            "name_": "Infer_8",
            "developer_": "",
            "source_": "",
            "desc_": "Universal Inference Node - Enables cross-platform model deployment with multiple inference backends while maintaining native performance",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": true,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "CvtTokenIds2Tensor_6@output_0",
                    "type_": "Tensor"
                }
            ],
            "is_dynamic_output_": true,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "Infer_8@output_0",
                    "type_": "Tensor"
                }
            ],
            "node_type_": "Intermediate",
            "type_": "kInferenceTypeOnnxRuntime",
            "param_": {
                "required_params_": [
                    "inference_type_",
                    "model_type_",
                    "model_value_",
                    "device_type_"
                ],
                "model_type_": "kModelTypeOnnx",
                "is_path_": true,
                "model_value_": [
                    "resources/models/stable_diffusion/fp32/text_encoder/model.onnx"
                ],
                "external_model_data_": [
                    ""
                ],
                "device_type_": "kDeviceTypeCodeCpu:0",
                "num_thread_": 4,
                "gpu_tune_kernel_": 1,
                "input_num_": 1,
                "input_name_": [
                    ""
                ],
                "input_shape_": [
                    [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                ],
                "output_num_": 1,
                "output_name_": [
                    ""
                ],
                "encrypt_type_": "kEncryptTypeNone",
                "license_": "",
                "share_memory_mode_": "kShareMemoryTypeNoShare",
                "precision_type_": "kPrecisionTypeFp32",
                "power_type_": "kPowerTypeNormal",
                "is_dynamic_shape_": false,
                "min_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "opt_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "max_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "parallel_type_": "kParallelTypeNone",
                "worker_num_": 1
            },
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::stable_diffusion::ConcatEmbedding",
            "name_": "ConcatEmbedding_9",
            "developer_": "",
            "source_": "",
            "desc_": "Concatenate prompt and negative prompt embeddings for classifier-free guidance.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "Infer_7@output_0",
                    "type_": "Tensor"
                },
                {
                    "desc_": "input_1",
                    "name_": "Infer_8@output_0",
                    "type_": "Tensor"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "ConcatEmbedding_9@output_0",
                    "type_": "Tensor"
                }
            ],
            "node_type_": "Intermediate",
            "guidance_": 7.5,
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::stable_diffusion::InitLatents",
            "name_": "InitLatents_10",
            "developer_": "",
            "source_": "",
            "desc_": "Initialize random latent tensor for DDIM sampling.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "InitLatents_10@output_0",
                    "type_": "Tensor"
                }
            ],
            "node_type_": "Input",
            "param_": {
                "version_": "v1.5",
                "num_train_timesteps_": 1000,
                "clip_sample_": false,
                "num_inference_steps_": 50,
                "unet_channels_": 4,
                "image_height_": 512,
                "image_width_": 512,
                "guidance_scale_": 7.5,
                "vae_scale_factor_": 0.1821500062942505,
                "init_noise_sigma_": 1,
                "beta_start_": 0.0008500000112690032,
                "beta_end_": 0.012000000104308128,
                "beta_schedule_": "scaled_linear",
                "eta_": 0,
                "set_alpha_to_one_": false
            },
            "size_": 1,
            "size": {
                "width": 171.33802816901408,
                "height": 98.2394366197183
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::stable_diffusion::Denoise",
            "name_": "Denoise_11",
            "developer_": "",
            "source_": "",
            "desc_": "Denoise latents loop: apply UNet and DDIM scheduler with optional classifier-free guidance.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "InitLatents_10@output_0",
                    "type_": "Tensor"
                },
                {
                    "desc_": "input_1",
                    "name_": "ConcatEmbedding_9@output_0",
                    "type_": "Tensor"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "Denoise_11@output_0",
                    "type_": "Tensor"
                }
            ],
            "is_composite_node_": true,
            "node_type_": "Intermediate",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": [
                {
                    "key_": "nndeploy::infer::Infer",
                    "name_": "unet_infer",
                    "developer_": "",
                    "source_": "",
                    "desc_": "Universal Inference Node - Enables cross-platform model deployment with multiple inference backends while maintaining native performance",
                    "device_type_": "kDeviceTypeCodeCpu:0",
                    "version_": "1.0.0",
                    "required_params_": [],
                    "is_dynamic_input_": true,
                    "inputs_": [
                        {
                            "desc_": "input_0",
                            "type_": "Tensor"
                        },
                        {
                            "desc_": "input_1",
                            "type_": "NotSet"
                        },
                        {
                            "desc_": "input_2",
                            "type_": "NotSet"
                        }
                    ],
                    "is_dynamic_output_": true,
                    "outputs_": [
                        {
                            "desc_": "output_0",
                            "type_": "Tensor"
                        }
                    ],
                    "node_type_": "Intermediate",
                    "type_": "kInferenceTypeOnnxRuntime",
                    "param_": {
                        "required_params_": [
                            "inference_type_",
                            "model_type_",
                            "model_value_",
                            "device_type_"
                        ],
                        "model_type_": "kModelTypeOnnx",
                        "is_path_": true,
                        "model_value_": [
                            "resources/models/stable_diffusion/fp32/unet/model.onnx"
                        ],
                        "external_model_data_": [
                            "resources/models/stable_diffusion/fp32/unet/weights.pb"
                        ],
                        "device_type_": "kDeviceTypeCodeCpu:0",
                        "num_thread_": 4,
                        "gpu_tune_kernel_": 1,
                        "input_num_": 1,
                        "input_name_": [
                            ""
                        ],
                        "input_shape_": [
                            [
                                -1,
                                -1,
                                -1,
                                -1
                            ]
                        ],
                        "output_num_": 1,
                        "output_name_": [
                            ""
                        ],
                        "encrypt_type_": "kEncryptTypeNone",
                        "license_": "",
                        "share_memory_mode_": "kShareMemoryTypeNoShare",
                        "precision_type_": "kPrecisionTypeFp32",
                        "power_type_": "kPowerTypeNormal",
                        "is_dynamic_shape_": false,
                        "min_shape_": {
                            "input_0": [
                                -1,
                                -1,
                                -1,
                                -1
                            ]
                        },
                        "opt_shape_": {
                            "input_0": [
                                -1,
                                -1,
                                -1,
                                -1
                            ]
                        },
                        "max_shape_": {
                            "input_0": [
                                -1,
                                -1,
                                -1,
                                -1
                            ]
                        },
                        "parallel_type_": "kParallelTypeNone",
                        "worker_num_": 1
                    },
                    "node_repository_": []
                },
                {
                    "key_": "nndeploy::stable_diffusion::DDIMSchedule",
                    "name_": "ddim_schedule",
                    "developer_": "",
                    "source_": "",
                    "desc_": "DDIM scheduler step: [unet_output, latents, timestep] -> updated latents with optional classifier-free guidance.",
                    "device_type_": "kDeviceTypeCodeCpu:0",
                    "version_": "1.0.0",
                    "required_params_": [],
                    "is_dynamic_input_": false,
                    "inputs_": [
                        {
                            "desc_": "input_0",
                            "type_": "Tensor"
                        },
                        {
                            "desc_": "input_1",
                            "type_": "Tensor"
                        },
                        {
                            "desc_": "input_2",
                            "type_": "Tensor"
                        }
                    ],
                    "is_dynamic_output_": false,
                    "outputs_": [
                        {
                            "desc_": "output_0",
                            "type_": "Tensor"
                        }
                    ],
                    "node_type_": "Intermediate",
                    "param_": {
                        "version_": "v1.5",
                        "num_train_timesteps_": 1000,
                        "clip_sample_": false,
                        "num_inference_steps_": 50,
                        "unet_channels_": 4,
                        "image_height_": 512,
                        "image_width_": 512,
                        "guidance_scale_": 7.5,
                        "vae_scale_factor_": 0.1821500062942505,
                        "init_noise_sigma_": 1,
                        "beta_start_": 0.0008500000112690032,
                        "beta_end_": 0.012000000104308128,
                        "beta_schedule_": "scaled_linear",
                        "eta_": 0,
                        "set_alpha_to_one_": false
                    },
                    "node_repository_": []
                }
            ]
        },
        {
            "key_": "nndeploy::stable_diffusion::ScaleLatents",
            "name_": "ScaleLatents_12",
            "developer_": "",
            "source_": "",
            "desc_": "stable_diffusion scale latents [device::Tensor->device::Tensor]",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "Denoise_11@output_0",
                    "type_": "Tensor"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "ScaleLatents_12@output_0",
                    "type_": "Tensor"
                }
            ],
            "node_type_": "Intermediate",
            "param_": {
                "vae_scale_factor_": 0.1821500062942505
            },
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::infer::Infer",
            "name_": "Infer_13",
            "developer_": "",
            "source_": "",
            "desc_": "Universal Inference Node - Enables cross-platform model deployment with multiple inference backends while maintaining native performance",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": true,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "ScaleLatents_12@output_0",
                    "type_": "Tensor"
                }
            ],
            "is_dynamic_output_": true,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "Infer_13@output_0",
                    "type_": "Tensor"
                }
            ],
            "node_type_": "Intermediate",
            "type_": "kInferenceTypeOnnxRuntime",
            "param_": {
                "required_params_": [
                    "inference_type_",
                    "model_type_",
                    "model_value_",
                    "device_type_"
                ],
                "model_type_": "kModelTypeOnnx",
                "is_path_": true,
                "model_value_": [
                    "resources/models/stable_diffusion/fp32/vae_decoder/model.onnx"
                ],
                "external_model_data_": [
                    ""
                ],
                "device_type_": "kDeviceTypeCodeCpu:0",
                "num_thread_": 4,
                "gpu_tune_kernel_": 1,
                "input_num_": 1,
                "input_name_": [
                    ""
                ],
                "input_shape_": [
                    [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                ],
                "output_num_": 1,
                "output_name_": [
                    ""
                ],
                "encrypt_type_": "kEncryptTypeNone",
                "license_": "",
                "share_memory_mode_": "kShareMemoryTypeNoShare",
                "precision_type_": "kPrecisionTypeFp32",
                "power_type_": "kPowerTypeNormal",
                "is_dynamic_shape_": false,
                "min_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "opt_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "max_shape_": {
                    "input_0": [
                        -1,
                        -1,
                        -1,
                        -1
                    ]
                },
                "parallel_type_": "kParallelTypeNone",
                "worker_num_": 1
            },
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::stable_diffusion::TensorToMat",
            "name_": "TensorToMat_14",
            "developer_": "",
            "source_": "",
            "desc_": "Convert float tensor to cv::Mat image.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "Infer_13@output_0",
                    "type_": "Tensor"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "TensorToMat_14@output_0",
                    "type_": "ndarray"
                }
            ],
            "node_type_": "Intermediate",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::codec::OpenCvImageEncode",
            "name_": "OpenCvImageEncode_15",
            "developer_": "",
            "source_": "",
            "desc_": "Encode image using OpenCV, from cv::Mat to image file, supports common image formats",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "path_"
            ],
            "ui_params_": [],
            "io_params_": [],
            "dropdown_params_": {},
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "name_": "TensorToMat_14@output_0",
                    "type_": "ndarray"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [],
            "node_type_": "Output",
            "io_type_": "Image",
            "path_": "resources/images/apple_fp32.png",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::stable_diffusion::InitTokenText",
            "name_": "InitTokenText_16",
            "developer_": "",
            "source_": "",
            "desc_": "Create TokenizerText from input prompt string.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "prompt_"
            ],
            "ui_params_": [],
            "io_params_": [],
            "dropdown_params_": {},
            "is_dynamic_input_": false,
            "inputs_": [],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "InitTokenText_16@output_0",
                    "type_": "TokenizerText"
                }
            ],
            "node_type_": "Input",
            "io_type_": "String",
            "prompt_": "a red apple",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::stable_diffusion::InitTokenText",
            "name_": "InitTokenText_17",
            "developer_": "",
            "source_": "",
            "desc_": "Create TokenizerText from input prompt string.",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "prompt_"
            ],
            "ui_params_": [],
            "io_params_": [],
            "dropdown_params_": {},
            "is_dynamic_input_": false,
            "inputs_": [],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "name_": "InitTokenText_17@output_0",
                    "type_": "TokenizerText"
                }
            ],
            "node_type_": "Input",
            "io_type_": "String",
            "prompt_": "",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        }
    ],
    "nndeploy_ui_layout": {
        "layout": {
            "TokenizerEncodeCpp_3": {
                "position": {
                    "x": 400,
                    "y": 23.80000000000001
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "TokenizerEncodeCpp_4": {
                "position": {
                    "x": 400,
                    "y": 246.3
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "CvtTokenIds2Tensor_5": {
                "position": {
                    "x": 700,
                    "y": 23.80000000000001
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "CvtTokenIds2Tensor_6": {
                "position": {
                    "x": 700,
                    "y": 246.3
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "Infer_7": {
                "position": {
                    "x": 1000,
                    "y": 23.80000000000001
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "Infer_8": {
                "position": {
                    "x": 1000,
                    "y": 246.3
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "ConcatEmbedding_9": {
                "position": {
                    "x": 1300,
                    "y": 124.14999999999998
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "InitLatents_10": {
                "position": {
                    "x": 1300,
                    "y": 320.84999999999997
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "Denoise_11": {
                "position": {
                    "x": 1515,
                    "y": 62
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true,
                "children": {
                    "unet_infer": {
                        "position": {
                            "x": 100,
                            "y": 0
                        },
                        "size": {
                            "width": 200,
                            "height": 80
                        },
                        "expanded": true
                    },
                    "ddim_schedule": {
                        "position": {
                            "x": 100,
                            "y": 218.39999999999998
                        },
                        "size": {
                            "width": 200,
                            "height": 80
                        },
                        "expanded": true
                    }
                }
            },
            "ScaleLatents_12": {
                "position": {
                    "x": 1930,
                    "y": 227.95
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "Infer_13": {
                "position": {
                    "x": 2230,
                    "y": 227.95
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "TensorToMat_14": {
                "position": {
                    "x": 2530,
                    "y": 227.95
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "OpenCvImageEncode_15": {
                "position": {
                    "x": 2830,
                    "y": 224.95
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "InitTokenText_16": {
                "position": {
                    "x": 100,
                    "y": 0
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            },
            "InitTokenText_17": {
                "position": {
                    "x": 100,
                    "y": 222.5
                },
                "size": {
                    "width": 200,
                    "height": 80
                },
                "expanded": true
            }
        },
        "groups": []
    }
}